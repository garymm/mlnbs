{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601519180062",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering\n",
    "\n",
    "An attempt to match fastai's performance on [MovieLens 100K](https://grouplens.org/datasets/movielens/100k/), but with pure pytorch, not using fastai's library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import fastai\n",
    "import fastai.collab\n",
    "import fastai.datasets\n",
    "import fastai.tabular.transform\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import typing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cpu\") # Seems to be much faster than GPU for this application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_path = fastai.datasets.download_data(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\", ext=\"\")\n",
    "dest_dir = zip_path.parent\n",
    "data_dir = os.path.splitext(zip_path)[0]\n",
    "if not os.path.exists(data_dir):\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        zf.extractall(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n_item: 1682, n_user: 943\n"
    }
   ],
   "source": [
    "col_names = (\"user\", \"item\", \"rating\", \"timestamp\")\n",
    "train_df = pandas.read_csv(os.path.join(data_dir, \"ua.base\"), sep=\"\\t\", names=col_names)\n",
    "test_df = pandas.read_csv(os.path.join(data_dir, \"ua.test\"), sep=\"\\t\", names=col_names)\n",
    "concat_df = pandas.concat((train_df, test_df))\n",
    "n_item = concat_df[\"item\"].max()\n",
    "n_user = concat_df[\"user\"].max()\n",
    "print(f\"n_item: {n_item}, n_user: {n_user}\")\n",
    "\n",
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pandas.DataFrame, device: torch.device):\n",
    "        # Indices into embeddings need to have dtype \"long\".\n",
    "        self.ids_tensor = torch.tensor(df[[\"user\", \"item\"]].to_numpy(), dtype=torch.long, device=device)\n",
    "        self.ratings_tensor = torch.tensor(df[[\"rating\"]].to_numpy(), dtype=torch.float, device=device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.ids_tensor[idx], self.ratings_tensor[idx]\n",
    "        \n",
    "\n",
    "train_dataset = MovieLensDataset(train_df, dev)\n",
    "test_dataset = MovieLensDataset(test_df, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_inputs, test_labels = test_dataset[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastai benchmark\n",
    "fastai claims state of the art performance, so let's start with that and see how it does.\n",
    "This is based on <https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson4-collab.ipynb>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>user</th>\n      <th>item</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>592</td>\n      <td>405</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <td>659</td>\n      <td>319</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <td>561</td>\n      <td>510</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <td>519</td>\n      <td>350</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <td>194</td>\n      <td>89</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Hacked up copy of CollabDataBunch.from_df because I want to use test_df as the validation set.\n",
    "user_name   = concat_df.columns[0]\n",
    "item_name   = concat_df.columns[1]\n",
    "rating_name = concat_df.columns[2]\n",
    "cat_names = [user_name,item_name]\n",
    "num_train = len(train_df)\n",
    "src = (fastai.collab.CollabList.from_df(concat_df, cat_names=cat_names, procs=fastai.tabular.transform.Categorify)\n",
    "        .split_by_idxs(train_idx=numpy.arange(num_train), valid_idx=numpy.arange(num_train, num_train + len(test_df)))\n",
    "        .label_from_df(cols=rating_name))\n",
    "data_bunch = src.databunch(path=\".\", bs=batch_size, val_bs=batch_size, device=dev)\n",
    "assert len(data_bunch.dl(fastai.basic_data.DatasetType.Train).dl.dataset.x) == num_train\n",
    "data_bunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.930389</td>\n      <td>1.043625</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.881159</td>\n      <td>0.995233</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.870824</td>\n      <td>0.959754</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.841655</td>\n      <td>0.946414</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.787724</td>\n      <td>0.941334</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.717227</td>\n      <td>0.917258</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.632812</td>\n      <td>0.902190</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.522469</td>\n      <td>0.895359</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.416748</td>\n      <td>0.898977</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.333631</td>\n      <td>0.900505</td>\n      <td>00:08</td>\n    </tr>\n  </tbody>\n</table>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fastai_learn = fastai.collab.collab_learner(data_bunch, n_factors=40, y_range=[0,5.5], wd=1e-1)\n",
    "fastai_learn.fit_one_cycle(num_epochs, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": "",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fastai_pred = fastai_learn.get_preds(ds_type=fastai.data_block.DatasetType.Valid)\n",
    "torch.nn.functional.mse_loss(*fastai_pred).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Fitter:\n",
    "    def __init__(self, model: nn.Module, loss_func: nn.Module, optim: torch.optim.Optimizer):\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.optim = optim\n",
    "        self.losses = []\n",
    "\n",
    "    def fit(self, num_epochs: int):\n",
    "        print(\"epoch | train_loss | test_loss | time\")\n",
    "        for epoch in range(num_epochs):\n",
    "            start = time.time()\n",
    "            train_loss = torch.tensor([0.0], dtype=float, device=dev)\n",
    "            self.model.train()\n",
    "            for batch_idx, (inputs, targets) in enumerate(train_loader, 0):\n",
    "                train_loss += self._one_batch(inputs, targets)\n",
    "\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                # Convert from 1-based to 0-based index.\n",
    "                pred = self.model(test_inputs[:, 0] - 1, test_inputs[:, 1] - 1)\n",
    "                test_loss = self.loss_func(pred, test_labels).item()\n",
    "\n",
    "            num_batches = batch_idx + 1\n",
    "            self.losses.append((train_loss / num_batches, test_loss))\n",
    "            print(\"%5d |      %.3f |     %.3f |   %ds |\" % (\n",
    "                epoch,\n",
    "                self.losses[-1][0],\n",
    "                self.losses[-1][1],\n",
    "                int(time.time() - start)))\n",
    "\n",
    "    def _one_batch(self, inputs: torch.tensor, targets: torch.tensor) -> torch.tensor:\n",
    "        # Convert from 1-based to 0-based index.\n",
    "        users, items = inputs[:, 0] - 1, inputs[:, 1] - 1\n",
    "        pred = self.model(users, items)\n",
    "        loss = self.loss_func(pred, targets)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        self.optim.zero_grad()\n",
    "        return loss\n",
    "\n",
    "class FitterOneCycle(Fitter):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(*args)\n",
    "        self.scheduler = None\n",
    "    \n",
    "    def fit(self, num_epochs: int):\n",
    "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            self.optim, max_lr=1e-2,\n",
    "            final_div_factor=25e4, # Copying fastai\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=math.ceil(len(train_df) / batch_size))\n",
    "        super().fit(num_epochs)\n",
    "\n",
    "    def _one_batch(self, inputs: torch.tensor, targets: torch.tensor) -> torch.tensor:\n",
    "        loss = super()._one_batch(inputs, targets)\n",
    "        self.scheduler.step()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_normal_(x: torch.tensor, mean: float=0., std: float=1.) -> torch.tensor:\n",
    "    \"Truncated normal initialization.\"\n",
    "    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n",
    "    return x.normal_().fmod_(2).mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProdBias(nn.Module):\n",
    "    \"\"\"Same as DotProdBias, but scale the output to be within y_range.\"\"\"\n",
    "    def __init__(self, n_user: int, n_item: int, embedding_dim: int, y_range: typing.Tuple[int, int], trunc_normal: bool=False):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_embeddings=n_user, embedding_dim=embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_embeddings=n_item, embedding_dim=embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_embeddings=n_user, embedding_dim=1)\n",
    "        self.item_bias = nn.Embedding(num_embeddings=n_item, embedding_dim=1)\n",
    "        if trunc_normal:\n",
    "            # Based on\n",
    "            # https://github.com/fastai/fastai1/blob/6a5102ef7bdefa9058d0481ab311f48b21cbc6fc/fastai/layers.py#L285\n",
    "            for e in (self.user_emb, self.item_emb, self.user_bias, self.item_bias):\n",
    "                with torch.no_grad(): trunc_normal_(e.weight, std=0.01)\n",
    "        self.y_min, self.y_max = y_range\n",
    "    \n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor) -> torch.FloatTensor:\n",
    "        dot_prods = (self.user_emb(users) * self.item_emb(items)).sum(dim=1)\n",
    "        u_bias = self.user_bias(users)\n",
    "        u_bias_view = u_bias.view(u_bias.size(0))\n",
    "        i_bias = self.item_bias(items)\n",
    "        i_bias_view = i_bias.view(i_bias.size(0))\n",
    "        biased = dot_prods + u_bias_view + i_bias_view\n",
    "        res = self.y_min + (self.y_max - self.y_min) * nn.functional.sigmoid(biased)\n",
    "        import pdb; pdb.set_trace()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n> \u001b[0;32m<ipython-input-51-df6831001428>\u001b[0m(25)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n\u001b[0;32m     21 \u001b[0;31m        \u001b[0mi_bias_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22 \u001b[0;31m        \u001b[0mbiased\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_prods\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mu_bias_view\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi_bias_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23 \u001b[0;31m        \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_max\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_min\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiased\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m---> 25 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\ntorch.Size([64, 1])\ntorch.Size([64])\ntensor([-0.0036], grad_fn=<SelectBackward>)\ntensor(-0.0036, grad_fn=<SelectBackward>)\ntorch.Size([64])\ntorch.Size([64])\ntorch.Size([64, 64])\ntorch.Size([64, 64])\n"
    },
    {
     "output_type": "error",
     "ename": "BdbQuit",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-965371d916c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     torch.optim.AdamW(model.parameters(), betas=(0.9, 0.99)))\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfitter_one_cycle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-c2caae939cb9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             steps_per_epoch=math.ceil(len(train_df) / batch_size))\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c2caae939cb9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c2caae939cb9>\u001b[0m in \u001b[0;36m_one_batch\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c2caae939cb9>\u001b[0m in \u001b[0;36m_one_batch\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Convert from 1-based to 0-based index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-df6831001428>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, users, items)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_max\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_min\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiased\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-df6831001428>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, users, items)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_min\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_max\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_min\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiased\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/fastai1/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ScaledDotProdBias(n_user, n_item, 40, (0.5, 5.5), trunc_normal=True).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(\n",
    "    model,\n",
    "    nn.MSELoss(),\n",
    "    torch.optim.AdamW(model.parameters(), betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prev = 0.831, 0.920\n",
    "prev = fitter_one_cycle.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO ##\n",
    " * look into OneCycleLR parameters vs fastai's implementation\n",
    "    * learning rates are the same\n",
    "    * fastai's opt.mom is the same as pytorch's betas[0]\n",
    "    * what is betas[1]?\n",
    " * But something is likely different either in OneCycleLR and/or in AdamW, because I think those are the main differences.\n"
   ]
  }
 ]
}