{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601339400458",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import fastai\n",
    "import fastai.collab\n",
    "import fastai.datasets\n",
    "import fastai.tabular.transform\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import typing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = torch.device(\"cuda:0\")\n",
    "CPU = torch.device(\"cpu\")\n",
    "dev = CPU # Seems to be much faster for this application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_path = fastai.datasets.download_data(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\", ext=\"\")\n",
    "dest_dir = zip_path.parent\n",
    "data_dir = os.path.splitext(zip_path)[0]\n",
    "if not os.path.exists(data_dir):\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        zf.extractall(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n_item: 1682, n_user: 943\n"
    }
   ],
   "source": [
    "col_names = (\"user\", \"item\", \"rating\", \"timestamp\")\n",
    "train_df = pandas.read_csv(os.path.join(data_dir, \"ua.base\"), sep=\"\\t\", names=col_names)\n",
    "test_df = pandas.read_csv(os.path.join(data_dir, \"ua.test\"), sep=\"\\t\", names=col_names)\n",
    "concat_df = pandas.concat((train_df, test_df))\n",
    "n_item = max(train_df[\"item\"].max(), test_df[\"item\"].max())\n",
    "n_user = max(train_df[\"user\"].max(), test_df[\"user\"].max())\n",
    "print(f\"n_item: {n_item}, n_user: {n_user}\")\n",
    "\n",
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pandas.DataFrame, device: torch.device):\n",
    "        # Indices into embeddings need to have dtype \"long\".\n",
    "        self.ids_tensor = torch.tensor(df[[\"user\", \"item\"]].to_numpy(), dtype=torch.long, device=device)\n",
    "        self.ratings_tensor = torch.tensor(df[[\"rating\"]].to_numpy(), dtype=torch.float, device=device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.ids_tensor[idx], self.ratings_tensor[idx]\n",
    "        \n",
    "\n",
    "train_dataset = MovieLensDataset(train_df, dev)\n",
    "test_dataset = MovieLensDataset(test_df, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_inputs, test_labels = test_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>user</th>\n      <th>item</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>13</td>\n      <td>692</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <td>308</td>\n      <td>378</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <td>747</td>\n      <td>268</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>410</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <td>417</td>\n      <td>582</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on DeviceDataLoader in module fastai.basic_data object:\n\nclass DeviceDataLoader(builtins.object)\n |  DeviceDataLoader(dl: torch.utils.data.dataloader.DataLoader, device: torch.device, tfms: List[Callable] = None, collate_fn: Callable = <function data_collate at 0x7f82d2a75820>) -> None\n |  \n |  Bind a `DataLoader` to a `torch.device`.\n |  \n |  Methods defined here:\n |  \n |  __eq__(self, other)\n |  \n |  __getattr__(self, k: str) -> Any\n |  \n |  __init__(self, dl: torch.utils.data.dataloader.DataLoader, device: torch.device, tfms: List[Callable] = None, collate_fn: Callable = <function data_collate at 0x7f82d2a75820>) -> None\n |  \n |  __iter__(self)\n |      Process and returns items from `DataLoader`.\n |  \n |  __len__(self) -> int\n |  \n |  __post_init__(self)\n |  \n |  __repr__(self)\n |  \n |  __setstate__(self, data: Any)\n |  \n |  add_tfm(self, tfm: Callable) -> None\n |      Add `tfm` to `self.tfms`.\n |  \n |  collate_fn = data_collate(batch: Collection[Union[torch.Tensor, fastai.core.ItemBase, ForwardRef('ItemsList'), float, int]]) -> torch.Tensor\n |      Convert `batch` items to tensor data.\n |  \n |  new(self, **kwargs)\n |      Create a new copy of `self` with `kwargs` replacing current values.\n |  \n |  proc_batch(self, b: torch.Tensor) -> torch.Tensor\n |      Process batch `b` of `TensorImage`.\n |  \n |  remove_tfm(self, tfm: Callable) -> None\n |      Remove `tfm` from `self.tfms`.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods defined here:\n |  \n |  create(dataset: torch.utils.data.dataset.Dataset, bs: int = 64, shuffle: bool = False, device: torch.device = device(type='cuda'), tfms: Collection[Callable] = None, num_workers: int = 8, collate_fn: Callable = <function data_collate at 0x7f82d2a75820>, **kwargs: Any) from builtins.type\n |      Create DeviceDataLoader from `dataset` with `bs` and `shuffle`: process using `num_workers`.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  batch_size\n |  \n |  num_workers\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __annotations__ = {'collate_fn': typing.Callable, 'device': <class 'to...\n |  \n |  __dataclass_fields__ = {'collate_fn': Field(name='collate_fn',type=typ...\n |  \n |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n |  \n |  __hash__ = None\n |  \n |  tfms = None\n\n"
    }
   ],
   "source": [
    "# Use fastai as a benchmark.\n",
    "# See https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson4-collab.ipynb\n",
    "# Hacked up copy of CollabDataBunch.from_df because I want to use test_df as the validation set.\n",
    "user_name   = concat_df.columns[0]\n",
    "item_name   = concat_df.columns[1]\n",
    "rating_name = concat_df.columns[2]\n",
    "cat_names = [user_name,item_name]\n",
    "num_train = len(train_df)\n",
    "src = (fastai.collab.CollabList.from_df(concat_df, cat_names=cat_names, procs=fastai.tabular.transform.Categorify)\n",
    "        .split_by_idxs(train_idx=numpy.arange(num_train), valid_idx=numpy.arange(num_train, num_train + len(test_df)))\n",
    "        .label_from_df(cols=rating_name))\n",
    "data_bunch = src.databunch(path=\".\", bs=batch_size, val_bs=batch_size, device=dev)\n",
    "assert len(data_bunch.dl(fastai.basic_data.DatasetType.Train).dl.dataset.x) == num_train\n",
    "data_bunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.947493</td>\n      <td>1.052847</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.877937</td>\n      <td>0.965214</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.877414</td>\n      <td>0.963883</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.854461</td>\n      <td>0.941553</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.773689</td>\n      <td>0.939386</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.725790</td>\n      <td>0.912324</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.615820</td>\n      <td>0.902836</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.509327</td>\n      <td>0.895727</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.419247</td>\n      <td>0.896176</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.330990</td>\n      <td>0.896819</td>\n      <td>00:07</td>\n    </tr>\n  </tbody>\n</table>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fastai_learn = fastai.collab.collab_learner(data_bunch, n_factors=40, y_range=[0,5.5], wd=1e-1)\n",
    "fastai_learn.fit_one_cycle(num_epochs, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": "",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fastai_pred = fastai_learn.get_preds(ds_type=fastai.data_block.DatasetType.Valid)\n",
    "print(\"final fastai valid_loss = %.3f\" % torch.nn.functional.mse_loss(*fastai_pred).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProdBias(nn.Module):\n",
    "    \"\"\"Each user and item have embedding_dim params and a bias.\n",
    "\n",
    "    The predicted rating for (user, item) is\n",
    "      (x_user • x_item) + b_user + b_item\n",
    "    \"\"\"\n",
    "    def __init__(self, n_user: int, n_item: int, embedding_dim: int):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_embeddings=n_user, embedding_dim=embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_embeddings=n_item, embedding_dim=embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_embeddings=n_user, embedding_dim=1)\n",
    "        self.item_bias = nn.Embedding(num_embeddings=n_item, embedding_dim=1)\n",
    "    \n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor) -> torch.FloatTensor:\n",
    "        # Convert from 1-based to 0-based index.\n",
    "        users, items = users - 1, items - 1\n",
    "        dot_prods = (self.user_emb(users) * self.item_emb(items)).sum(dim=1)\n",
    "        return dot_prods + self.user_bias(users) + self.item_bias(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Fitter:\n",
    "    def __init__(self, model: nn.Module, loss_func: nn.Module, optim: torch.optim.Optimizer):\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.optim = optim\n",
    "\n",
    "    def fit(self, num_epochs: int):\n",
    "        print(\"epoch | train_loss | test_loss | time\")\n",
    "        for epoch in range(num_epochs):\n",
    "            start = time.time()\n",
    "            train_loss = torch.tensor([0.0], dtype=float, device=dev)\n",
    "            for batch_idx, (inputs, targets) in enumerate(train_loader, 0):\n",
    "                train_loss += self._one_batch(inputs, targets)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = self.model(test_inputs[:, 0], test_inputs[:, 1])\n",
    "                test_loss = self.loss_func(pred, test_labels).item()\n",
    "\n",
    "            num_batches = batch_idx + 1\n",
    "            print(\"%5d |      %.3f |     %.3f |   %ds |\" % (\n",
    "                epoch,\n",
    "                train_loss / num_batches,\n",
    "                test_loss,\n",
    "                int(time.time() - start)))\n",
    "\n",
    "    def _one_batch(self, inputs: torch.tensor, targets: torch.tensor) -> torch.tensor:\n",
    "        self.optim.zero_grad()\n",
    "        pred = self.model(inputs[:, 0], inputs[:, 1])\n",
    "        loss = self.loss_func(pred, targets)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time | num_batches\n    0 |      32.385 |     20.587 |  2s | 1416\n    1 |      7.093 |     9.406 |  3s | 1416\n    2 |      2.267 |     5.821 |  3s | 1416\n    3 |      1.325 |     4.394 |  3s | 1416\n    4 |      1.089 |     3.734 |  3s | 1416\n    5 |      1.017 |     3.262 |  3s | 1416\n    6 |      0.985 |     2.941 |  3s | 1416\n    7 |      0.965 |     2.685 |  2s | 1416\n    8 |      0.954 |     2.465 |  3s | 1416\n    9 |      0.940 |     2.284 |  3s | 1416\n"
    }
   ],
   "source": [
    "model_dot_prod_bias = DotProdBias(n_user, n_item, 40).to(dev)\n",
    "fitter_dot_prod_bias = Fitter(model_dot_prod_bias, nn.MSELoss(), torch.optim.Adam(model_dot_prod_bias.parameters(), lr=5e-3, betas=(0.9, 0.99)))\n",
    "fitter_dot_prod_bias.fit(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dot_prod_bias_path = \"model_dot_prod_bias.pth\"\n",
    "torch.save(model_dot_prod_bias.state_dict(), model_dot_prod_bias_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_normal_(x: torch.tensor, mean: float=0., std: float=1.) -> torch.tensor:\n",
    "    \"Truncated normal initialization.\"\n",
    "    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n",
    "    return x.normal_().fmod_(2).mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProdBias(nn.Module):\n",
    "    \"\"\"Same as DotProdBias, but scale the output to be within y_range.\"\"\"\n",
    "    def __init__(self, n_user: int, n_item: int, embedding_dim: int, y_range: typing.Tuple[int, int], trunc_normal: bool=False):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_embeddings=n_user, embedding_dim=embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_embeddings=n_item, embedding_dim=embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_embeddings=n_user, embedding_dim=1)\n",
    "        self.item_bias = nn.Embedding(num_embeddings=n_item, embedding_dim=1)\n",
    "        if trunc_normal:\n",
    "            # https://github.com/fastai/fastai1/blob/6a5102ef7bdefa9058d0481ab311f48b21cbc6fc/fastai/layers.py#L285\n",
    "            for e in (self.user_emb, self.item_emb, self.user_bias, self.item_bias):\n",
    "                with torch.no_grad(): trunc_normal_(e.weight, std=0.01)\n",
    "        self.y_min, self.y_max = y_range\n",
    "    \n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor) -> torch.FloatTensor:\n",
    "        # Convert from 1-based to 0-based index.\n",
    "        users, items = users - 1, items - 1\n",
    "        dot_prods = (self.user_emb(users) * self.item_emb(items)).sum(dim=1)\n",
    "        biased = dot_prods + self.user_bias(users) + self.item_bias(items)\n",
    "        return self.y_min + (self.y_max - self.y_min) * nn.functional.sigmoid(biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      7.755 |     6.754 | 4s\n    1 |      5.117 |     5.289 | 3s\n    2 |      3.834 |     4.599 | 3s\n    3 |      2.908 |     3.990 | 3s\n    4 |      2.060 |     3.375 | 3s\n    5 |      1.512 |     2.918 | 3s\n    6 |      1.257 |     2.601 | 3s\n    7 |      1.138 |     2.368 | 3s\n    8 |      1.079 |     2.189 | 3s\n    9 |      1.045 |     2.043 | 3s\n"
    }
   ],
   "source": [
    "model_scaled_dot_prod_bias = ScaledDotProdBias(n_user, n_item, 40, (-0.5, 5.5)).to(dev)\n",
    "fitter_scaled_dot_prod_bias = Fitter(model_scaled_dot_prod_bias, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias.parameters(), lr=5e-3, betas=(0.9, 0.99)))\n",
    "fitter_scaled_dot_prod_bias.fit(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scaled_dot_prod_bias_path = \"model_scaled_dot_prod_bias.pth\"\n",
    "torch.save(model_scaled_dot_prod_bias.state_dict(), model_scaled_dot_prod_bias_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitterOneCycle(Fitter):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(*args)\n",
    "        self.scheduler = None\n",
    "    \n",
    "    def fit(self, num_epochs: int):\n",
    "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optim, self.optim.defaults[\"lr\"], epochs=num_epochs, steps_per_epoch=math.ceil(len(train_df) / batch_size))\n",
    "        super().fit(num_epochs)\n",
    "\n",
    "    def _one_batch(self, inputs: torch.tensor, targets: torch.tensor) -> torch.tensor:\n",
    "        loss = super()._one_batch(inputs, targets)\n",
    "        self.scheduler.step()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      9.008 |     8.912 |   2s |\n    1 |      8.019 |     7.623 |   3s |\n    2 |      5.932 |     5.857 |   3s |\n    3 |      4.281 |     4.870 |   3s |\n    4 |      3.307 |     4.285 |   3s |\n    5 |      2.513 |     3.843 |   3s |\n    6 |      1.925 |     3.539 |   4s |\n    7 |      1.580 |     3.375 |   3s |\n    8 |      1.414 |     3.313 |   3s |\n    9 |      1.355 |     3.304 |   3s |\n"
    }
   ],
   "source": [
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (-0.5, 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=5e-3, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      8.962 |     8.560 |   3s |\n    1 |      7.094 |     6.255 |   3s |\n    2 |      4.448 |     4.438 |   3s |\n    3 |      2.863 |     3.301 |   3s |\n    4 |      1.745 |     2.520 |   3s |\n    5 |      1.307 |     2.088 |   3s |\n    6 |      1.104 |     1.874 |   3s |\n    7 |      0.978 |     1.763 |   3s |\n    8 |      0.904 |     1.738 |   3s |\n    9 |      0.873 |     1.734 |   3s |\n"
    }
   ],
   "source": [
    "# Let's try increasing lr\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (-0.5, 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      8.032 |     6.355 |   3s |\n    1 |      4.281 |     4.149 |   3s |\n    2 |      3.784 |     4.565 |   3s |\n    3 |      4.159 |     4.648 |   3s |\n    4 |      4.131 |     4.498 |   3s |\n    5 |      3.825 |     4.278 |   3s |\n    6 |      3.194 |     3.716 |   3s |\n    7 |      2.350 |     2.941 |   3s |\n    8 |      1.725 |     2.435 |   3s |\n    9 |      1.399 |     2.355 |   3s |\n"
    }
   ],
   "source": [
    "# Let's try increasing lr again\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (-0.5, 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=5e-2, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      8.959 |     8.992 |   2s |\n    1 |      8.165 |     8.119 |   3s |\n    2 |      6.458 |     6.432 |   3s |\n    3 |      4.583 |     4.893 |   3s |\n    4 |      3.204 |     3.809 |   3s |\n    5 |      2.045 |     2.845 |   3s |\n    6 |      1.483 |     2.264 |   3s |\n    7 |      1.273 |     1.872 |   3s |\n    8 |      1.150 |     1.660 |   3s |\n    9 |      1.075 |     1.477 |   3s |\n   10 |      1.018 |     1.342 |   3s |\n   11 |      0.974 |     1.268 |   3s |\n   12 |      0.940 |     1.210 |   3s |\n   13 |      0.910 |     1.165 |   3s |\n   14 |      0.886 |     1.135 |   3s |\n   15 |      0.867 |     1.116 |   3s |\n   16 |      0.853 |     1.104 |   3s |\n   17 |      0.842 |     1.100 |   3s |\n   18 |      0.836 |     1.097 |   3s |\n   19 |      0.832 |     1.097 |   3s |\n"
    }
   ],
   "source": [
    "# That was not good, let's go back to 1e-2, and try training longer\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (-0.5, 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      7.453 |     7.434 |   3s |\n    1 |      6.883 |     6.810 |   3s |\n    2 |      5.626 |     5.615 |   3s |\n    3 |      4.108 |     4.364 |   3s |\n    4 |      2.801 |     3.274 |   3s |\n    5 |      1.780 |     2.465 |   3s |\n    6 |      1.353 |     1.999 |   4s |\n    7 |      1.179 |     1.677 |   3s |\n    8 |      1.072 |     1.441 |   3s |\n    9 |      1.007 |     1.305 |   3s |\n   10 |      0.959 |     1.196 |   3s |\n   11 |      0.926 |     1.124 |   3s |\n   12 |      0.903 |     1.087 |   3s |\n   13 |      0.884 |     1.052 |   3s |\n   14 |      0.870 |     1.035 |   3s |\n   15 |      0.856 |     1.023 |   3s |\n   16 |      0.846 |     1.016 |   3s |\n   17 |      0.838 |     1.013 |   3s |\n   18 |      0.834 |     1.012 |   3s |\n   19 |      0.831 |     1.011 |   3s |\n"
    }
   ],
   "source": [
    "# Let's tweak y-range to start at 0\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (0., 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      6.203 |     6.216 |   3s |\n    1 |      5.811 |     5.814 |   3s |\n    2 |      4.914 |     5.001 |   3s |\n    3 |      3.687 |     3.921 |   3s |\n    4 |      2.425 |     2.863 |   3s |\n    5 |      1.561 |     2.172 |   3s |\n    6 |      1.259 |     1.759 |   3s |\n    7 |      1.114 |     1.512 |   3s |\n    8 |      1.028 |     1.323 |   3s |\n    9 |      0.974 |     1.204 |   3s |\n   10 |      0.937 |     1.125 |   3s |\n   11 |      0.910 |     1.077 |   3s |\n   12 |      0.890 |     1.044 |   3s |\n   13 |      0.874 |     1.018 |   3s |\n   14 |      0.862 |     1.003 |   3s |\n   15 |      0.851 |     0.994 |   3s |\n   16 |      0.843 |     0.988 |   3s |\n   17 |      0.837 |     0.987 |   3s |\n   18 |      0.832 |     0.986 |   3s |\n   19 |      0.830 |     0.986 |   3s |\n"
    }
   ],
   "source": [
    "# Let's tweak y-range to start at 0.5\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (0.5, 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      5.271 |     3.430 |   2s |\n    1 |      1.727 |     1.257 |   3s |\n    2 |      1.129 |     1.227 |   3s |\n    3 |      1.124 |     1.225 |   3s |\n    4 |      1.126 |     1.232 |   3s |\n    5 |      1.127 |     1.227 |   3s |\n    6 |      1.127 |     1.231 |   3s |\n    7 |      1.127 |     1.228 |   3s |\n    8 |      1.127 |     1.230 |   4s |\n    9 |      1.127 |     1.228 |   3s |\n   10 |      1.125 |     1.233 |   3s |\n   11 |      1.125 |     1.227 |   3s |\n   12 |      1.124 |     1.226 |   3s |\n   13 |      1.123 |     1.228 |   3s |\n   14 |      1.122 |     1.226 |   3s |\n   15 |      1.122 |     1.226 |   3s |\n   16 |      1.121 |     1.226 |   3s |\n   17 |      1.118 |     1.228 |   3s |\n   18 |      1.117 |     1.228 |   3s |\n   19 |      1.116 |     1.228 |   2s |\n"
    }
   ],
   "source": [
    "# Let's try weight decay\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (0.5, 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99), weight_decay=1e-2))\n",
    "fitter_one_cycle.fit(num_epochs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      5.423 |     3.773 |   2s |\n    1 |      1.922 |     1.205 |   2s |\n    2 |      1.051 |     1.135 |   3s |\n    3 |      1.037 |     1.132 |   3s |\n    4 |      1.039 |     1.136 |   3s |\n    5 |      1.043 |     1.143 |   3s |\n    6 |      1.042 |     1.136 |   3s |\n    7 |      1.041 |     1.138 |   3s |\n    8 |      1.041 |     1.141 |   3s |\n    9 |      1.040 |     1.144 |   3s |\n   10 |      1.039 |     1.132 |   3s |\n   11 |      1.037 |     1.136 |   3s |\n   12 |      1.037 |     1.130 |   3s |\n   13 |      1.034 |     1.135 |   3s |\n   14 |      1.033 |     1.136 |   3s |\n   15 |      1.032 |     1.134 |   3s |\n   16 |      1.029 |     1.135 |   3s |\n   17 |      1.027 |     1.135 |   3s |\n   18 |      1.025 |     1.135 |   3s |\n   19 |      1.022 |     1.135 |   2s |\n"
    }
   ],
   "source": [
    "# Let's try a little bit less weight decay\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (0.5, 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99), weight_decay=5e-3))\n",
    "fitter_one_cycle.fit(num_epochs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      6.271 |     6.275 |   3s |\n    1 |      6.041 |     6.117 |   2s |\n    2 |      5.651 |     5.828 |   3s |\n    3 |      5.048 |     5.367 |   3s |\n    4 |      4.274 |     4.760 |   3s |\n    5 |      3.418 |     4.057 |   3s |\n    6 |      2.542 |     3.316 |   3s |\n    7 |      1.783 |     2.626 |   3s |\n    8 |      1.379 |     2.169 |   3s |\n    9 |      1.212 |     1.847 |   3s |\n   10 |      1.131 |     1.583 |   3s |\n   11 |      1.061 |     1.393 |   3s |\n   12 |      1.007 |     1.247 |   3s |\n   13 |      0.968 |     1.165 |   3s |\n   14 |      0.944 |     1.100 |   3s |\n   15 |      0.927 |     1.063 |   3s |\n   16 |      0.917 |     1.032 |   3s |\n   17 |      0.907 |     1.010 |   3s |\n   18 |      0.902 |     0.998 |   3s |\n   19 |      0.894 |     0.985 |   3s |\n   20 |      0.890 |     0.979 |   3s |\n   21 |      0.883 |     0.969 |   3s |\n   22 |      0.879 |     0.965 |   3s |\n   23 |      0.874 |     0.958 |   3s |\n   24 |      0.870 |     0.955 |   3s |\n   25 |      0.865 |     0.947 |   3s |\n   26 |      0.861 |     0.947 |   3s |\n   27 |      0.857 |     0.945 |   3s |\n   28 |      0.854 |     0.944 |   3s |\n   29 |      0.850 |     0.941 |   3s |\n   30 |      0.846 |     0.940 |   3s |\n   31 |      0.844 |     0.938 |   3s |\n   32 |      0.840 |     0.937 |   3s |\n   33 |      0.837 |     0.936 |   3s |\n   34 |      0.835 |     0.936 |   3s |\n   35 |      0.833 |     0.935 |   3s |\n   36 |      0.831 |     0.935 |   3s |\n   37 |      0.830 |     0.935 |   3s |\n   38 |      0.829 |     0.935 |   3s |\n   39 |      0.828 |     0.935 |   3s |\n"
    }
   ],
   "source": [
    "# Seems weight decay isn't really helping. Let's go back to our best performing model and see how many epochs it takes before we over-fit\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (0.5, 5.5)).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      0.834 |     0.938 |   2s |\n    1 |      0.856 |     0.959 |   3s |\n    2 |      0.888 |     0.970 |   3s |\n    3 |      0.898 |     0.974 |   3s |\n    4 |      0.893 |     0.972 |   3s |\n    5 |      0.880 |     0.957 |   3s |\n    6 |      0.865 |     0.947 |   3s |\n    7 |      0.851 |     0.941 |   3s |\n    8 |      0.839 |     0.938 |   3s |\n    9 |      0.831 |     0.938 |   3s |\n"
    }
   ],
   "source": [
    "fitter_one_cycle.fit(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that after 35 epochs we don't see any improvement in test set, and after 40 we start to over-fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      1.317 |     1.161 |   3s |\n    1 |      1.009 |     0.997 |   2s |\n    2 |      0.900 |     0.944 |   3s |\n    3 |      0.878 |     0.944 |   3s |\n    4 |      0.885 |     0.955 |   3s |\n    5 |      0.894 |     0.970 |   3s |\n    6 |      0.895 |     0.971 |   3s |\n    7 |      0.896 |     0.972 |   3s |\n    8 |      0.891 |     0.965 |   3s |\n    9 |      0.887 |     0.962 |   4s |\n   10 |      0.879 |     0.959 |   3s |\n   11 |      0.873 |     0.954 |   3s |\n   12 |      0.865 |     0.946 |   3s |\n   13 |      0.858 |     0.942 |   3s |\n   14 |      0.851 |     0.937 |   3s |\n   15 |      0.845 |     0.935 |   3s |\n   16 |      0.839 |     0.935 |   3s |\n   17 |      0.834 |     0.934 |   3s |\n   18 |      0.831 |     0.934 |   3s |\n   19 |      0.829 |     0.934 |   3s |\n"
    }
   ],
   "source": [
    "# Let's try trunc_normal initialization\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (0.5, 5.5), trunc_normal=True).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      1.392 |     1.336 |   3s |\n    1 |      1.164 |     1.230 |   3s |\n    2 |      1.122 |     1.226 |   3s |\n    3 |      1.125 |     1.227 |   3s |\n    4 |      1.126 |     1.230 |   3s |\n    5 |      1.127 |     1.226 |   3s |\n    6 |      1.127 |     1.235 |   3s |\n    7 |      1.128 |     1.229 |   3s |\n    8 |      1.127 |     1.227 |   3s |\n    9 |      1.126 |     1.230 |   3s |\n   10 |      1.125 |     1.230 |   3s |\n   11 |      1.125 |     1.233 |   3s |\n   12 |      1.125 |     1.222 |   3s |\n   13 |      1.124 |     1.228 |   3s |\n   14 |      1.122 |     1.223 |   3s |\n   15 |      1.122 |     1.227 |   3s |\n   16 |      1.121 |     1.227 |   3s |\n   17 |      1.119 |     1.227 |   3s |\n   18 |      1.117 |     1.228 |   3s |\n   19 |      1.115 |     1.228 |   3s |\n"
    }
   ],
   "source": [
    "# Wow, that really sped things up! Seems we're over-fitting after 5 epochs now. Let's try weight_decay again.\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (0.5, 5.5), trunc_normal=True).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.Adam(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99), weight_decay=1e-2))\n",
    "fitter_one_cycle.fit(num_epochs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch | train_loss | test_loss | time\n    0 |      1.314 |     1.161 |   3s |\n    1 |      1.009 |     0.997 |   3s |\n    2 |      0.902 |     0.947 |   3s |\n    3 |      0.881 |     0.942 |   3s |\n    4 |      0.883 |     0.951 |   3s |\n    5 |      0.890 |     0.952 |   3s |\n    6 |      0.893 |     0.959 |   3s |\n    7 |      0.890 |     0.958 |   3s |\n    8 |      0.888 |     0.956 |   3s |\n    9 |      0.882 |     0.949 |   3s |\n   10 |      0.877 |     0.942 |   3s |\n   11 |      0.870 |     0.941 |   3s |\n   12 |      0.863 |     0.934 |   3s |\n   13 |      0.857 |     0.928 |   3s |\n   14 |      0.851 |     0.925 |   3s |\n   15 |      0.845 |     0.923 |   3s |\n   16 |      0.839 |     0.922 |   3s |\n   17 |      0.834 |     0.922 |   3s |\n   18 |      0.831 |     0.923 |   3s |\n   19 |      0.829 |     0.923 |   3s |\n"
    }
   ],
   "source": [
    "# Hmm, under-fitting now :-(\n",
    "# Let's try using fastai's \"true_wd\" algorithm.\n",
    "# I think that's been added to torch as AdamW, so let's use that instead of Adam.\n",
    "model_scaled_dot_prod_bias_one_cycle = ScaledDotProdBias(n_user, n_item, 40, (0.5, 5.5), trunc_normal=True).to(dev)\n",
    "fitter_one_cycle = FitterOneCycle(model_scaled_dot_prod_bias_one_cycle, nn.MSELoss(), torch.optim.AdamW(model_scaled_dot_prod_bias_one_cycle.parameters(), lr=1e-2, betas=(0.9, 0.99)))\n",
    "fitter_one_cycle.fit(num_epochs*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark is fastai's results from https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson4-collab.ipynb: 0.815 for validation set.\n",
    "\n",
    "TODOs\n",
    " * look into weight decay\n",
    "   * fastai has their own implementation that's here: https://github.com/fastai/fastai1/blob/bcef12e95405655481bb309761f8c552b51b2bd2/fastai/callback.py#L48\n",
    "   * this seemed to help in first few epochs but lead to under-fitting. In general I'm not seeing over-fitting so I don't think this would be helpful.ab\n",
    " * look into OneCycleLR parameters vs fastai's implementation\n"
   ]
  }
 ]
}